{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f673f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Hugging Face Data Pipeline...\n",
      "Loading data from Hugging Face Hub...\n",
      " Loading 'tanganke/stanford_cars' from Hugging Face Hub...\n",
      "âœ… Data Split: 6515 Train | 1629 Val | 8041 Test\n",
      "Initializing MobileNetV2...\n",
      "Starting Training on cuda...\n",
      "Epoch 1/30 | Loss: 5.2212 | Accuracy: 1.66%\n",
      "Epoch 2/30 | Loss: 4.6394 | Accuracy: 5.94%\n",
      "Epoch 3/30 | Loss: 3.9662 | Accuracy: 12.17%\n",
      "Epoch 4/30 | Loss: 3.3868 | Accuracy: 19.36%\n",
      "Epoch 5/30 | Loss: 2.9395 | Accuracy: 26.91%\n",
      "Epoch 6/30 | Loss: 2.5770 | Accuracy: 33.32%\n",
      "Epoch 7/30 | Loss: 2.2856 | Accuracy: 39.05%\n",
      "Epoch 8/30 | Loss: 2.0235 | Accuracy: 45.85%\n",
      "Epoch 9/30 | Loss: 1.8130 | Accuracy: 49.79%\n",
      "Epoch 10/30 | Loss: 1.6460 | Accuracy: 54.34%\n",
      "Epoch 11/30 | Loss: 1.4887 | Accuracy: 58.48%\n",
      "Epoch 12/30 | Loss: 1.3422 | Accuracy: 62.00%\n",
      "Epoch 13/30 | Loss: 1.2460 | Accuracy: 64.48%\n",
      "Epoch 14/30 | Loss: 1.1298 | Accuracy: 67.63%\n",
      "Epoch 15/30 | Loss: 1.0427 | Accuracy: 69.58%\n",
      "Epoch 16/30 | Loss: 0.9540 | Accuracy: 72.00%\n",
      "Epoch 17/30 | Loss: 0.8931 | Accuracy: 73.77%\n",
      "Epoch 18/30 | Loss: 0.8344 | Accuracy: 75.44%\n",
      "Epoch 19/30 | Loss: 0.7752 | Accuracy: 76.41%\n",
      "Epoch 20/30 | Loss: 0.7220 | Accuracy: 78.33%\n",
      "Epoch 21/30 | Loss: 0.6743 | Accuracy: 79.55%\n",
      "Epoch 22/30 | Loss: 0.6234 | Accuracy: 81.40%\n",
      "Epoch 23/30 | Loss: 0.5927 | Accuracy: 82.04%\n",
      "Epoch 24/30 | Loss: 0.5296 | Accuracy: 84.64%\n",
      "Epoch 25/30 | Loss: 0.5169 | Accuracy: 84.62%\n",
      "Epoch 26/30 | Loss: 0.4904 | Accuracy: 85.33%\n",
      "Epoch 27/30 | Loss: 0.4721 | Accuracy: 85.66%\n",
      "Epoch 28/30 | Loss: 0.4305 | Accuracy: 86.71%\n",
      "Epoch 29/30 | Loss: 0.4343 | Accuracy: 87.12%\n",
      "Epoch 30/30 | Loss: 0.3927 | Accuracy: 88.46%\n",
      "Training loop finished successfully!\n",
      "Saving model...\n",
      "Model saved as 'mobilenet_v2_stanford_cars.pth'\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import get_dataloaders\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "MODEL_SAVE_PATH = \"mobilenet_v2_stanford_cars.pth\"\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 196\n",
    "NUM_EPOCHS = 30\n",
    "IMG_SIZE = 224  # Image resolution for MobileNetV2\n",
    "\n",
    "# ==========================================\n",
    "# 2. MODEL ARCHITECTURE\n",
    "# ==========================================\n",
    "def get_mobilenet_model(num_classes=196):\n",
    "    # Load Pre-trained MobileNetV2\n",
    "    model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    # --- STRATEGY: FINE-TUNING ---\n",
    "    # 1. Freeze the early layers (generic features like lines/edges)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    # 2. Unfreeze the last few inverted residual blocks for better feature learning\n",
    "    # MobileNetV2 has features organized in a Sequential container\n",
    "    # Unfreeze the last 4 blocks (out of 19 total blocks)\n",
    "    for param in model.features[-4:].parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    # 3. Replace the Classifier Head with Higher Dropout\n",
    "    in_features = model.classifier[1].in_features  # MobileNetV2 has 1280 features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(in_features, 1024),  # Add an intermediate layer\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),                # INCREASED dropout\n",
    "        nn.Linear(1024, num_classes)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ==========================================\n",
    "# 3. TRAINING SKELETON\n",
    "# ==========================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"Initializing Hugging Face Data Pipeline...\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Load Data using HF pipeline (handles downloading, splitting, and transforms)\n",
    "        print(\"Loading data from Hugging Face Hub...\")\n",
    "        train_dl, val_dl, test_dl = get_dataloaders(\n",
    "            batch_size=BATCH_SIZE, \n",
    "            img_size=IMG_SIZE, \n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        print(\"Initializing MobileNetV2...\")\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = get_mobilenet_model(num_classes=NUM_CLASSES).to(device)\n",
    "        \n",
    "        # Hyperparameters\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        # Add weight_decay=1e-4\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "        \n",
    "        # Learning Rate Scheduler\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "        \n",
    "        print(f\"Starting Training on {device}...\")\n",
    "        \n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0 \n",
    "            total_samples = 0\n",
    "            \n",
    "            for images, labels in train_dl:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                # Track Accuracy during training to see progress\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_samples += labels.size(0)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            epoch_loss = running_loss / len(train_dl)\n",
    "            epoch_acc = 100 * correct_predictions / total_samples\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%\")\n",
    "            \n",
    "            # Update LR based on training loss (or validation loss if we computed it per epoch)\n",
    "            scheduler.step(epoch_loss)\n",
    "            \n",
    "        print(\"Training loop finished successfully!\")\n",
    "        print(\"Saving model...\")\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(f\"Model saved as '{MODEL_SAVE_PATH}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"\\n An error occurred during execution:\")\n",
    "        print(e)\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c5409d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
