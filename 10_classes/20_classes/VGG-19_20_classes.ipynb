{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1295aaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üöÄ VGG-19 From Scratch Training on 20 Random Classes\n",
      "============================================================\n",
      "\n",
      "üì¶ Loading data from Hugging Face Hub...\n",
      "üöÄ Loading 'tanganke/stanford_cars' from Hugging Face Hub...\n",
      "üìä Total classes in dataset: 196\n",
      "üéØ Selected 20 random classes: [6, 7, 8, 22, 23, 26, 28, 35, 55, 57, 59, 62, 70, 108, 139, 151, 163, 173, 188, 189]\n",
      "‚úÖ Filtered dataset size: 829 samples\n",
      "üìä Total classes in dataset: 196\n",
      "üéØ Selected 20 random classes: [6, 7, 8, 22, 23, 26, 28, 35, 55, 57, 59, 62, 70, 108, 139, 151, 163, 173, 188, 189]\n",
      "‚úÖ Filtered dataset size: 820 samples\n",
      "‚úÖ Data Split: 663 Train | 166 Val | 820 Test\n",
      "üìå Classes remapped to range: 0-19\n",
      "\n",
      "üéØ Selected Classes: [6, 7, 8, 22, 23, 26, 28, 35, 55, 57, 59, 62, 70, 108, 139, 151, 163, 173, 188, 189]\n",
      "üìä Number of Classes: 20\n",
      "üíª Using device: cuda\n",
      "\n",
      "ü§ñ Initializing VGG-19 from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11304\\1566989351.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # Mixed Precision for speed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèãÔ∏è Starting Training for 30 epochs...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11304\\1566989351.py:189: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11304\\1566989351.py:113: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 1/30] | Train Loss: 3.0240 | Train Acc: 4.98% | Val Loss: nan | Val Acc: 3.61%\n",
      "  ‚úÖ Best model saved! (Val Acc: 3.61%)\n",
      "Epoch [ 2/30] | Train Loss: 3.0150 | Train Acc: 5.28% | Val Loss: nan | Val Acc: 4.22%\n",
      "  ‚úÖ Best model saved! (Val Acc: 4.22%)\n",
      "Epoch [ 3/30] | Train Loss: 2.9796 | Train Acc: 7.09% | Val Loss: nan | Val Acc: 6.63%\n",
      "  ‚úÖ Best model saved! (Val Acc: 6.63%)\n",
      "Epoch [ 4/30] | Train Loss: 2.9576 | Train Acc: 6.33% | Val Loss: nan | Val Acc: 6.02%\n",
      "Epoch [ 5/30] | Train Loss: 2.9006 | Train Acc: 7.99% | Val Loss: nan | Val Acc: 12.05%\n",
      "  ‚úÖ Best model saved! (Val Acc: 12.05%)\n",
      "Epoch [ 6/30] | Train Loss: 2.8727 | Train Acc: 8.75% | Val Loss: nan | Val Acc: 9.64%\n",
      "Epoch [ 7/30] | Train Loss: 2.8504 | Train Acc: 10.11% | Val Loss: nan | Val Acc: 12.05%\n",
      "Epoch [ 8/30] | Train Loss: 2.8525 | Train Acc: 11.61% | Val Loss: nan | Val Acc: 12.05%\n",
      "Epoch [ 9/30] | Train Loss: 2.8510 | Train Acc: 8.90% | Val Loss: nan | Val Acc: 13.86%\n",
      "  ‚úÖ Best model saved! (Val Acc: 13.86%)\n",
      "Epoch [10/30] | Train Loss: 2.8155 | Train Acc: 11.76% | Val Loss: nan | Val Acc: 12.05%\n",
      "Epoch [11/30] | Train Loss: 2.7934 | Train Acc: 11.01% | Val Loss: nan | Val Acc: 8.43%\n",
      "Epoch [12/30] | Train Loss: 2.7942 | Train Acc: 11.01% | Val Loss: nan | Val Acc: 15.06%\n",
      "  ‚úÖ Best model saved! (Val Acc: 15.06%)\n",
      "Epoch [13/30] | Train Loss: 2.7812 | Train Acc: 13.88% | Val Loss: nan | Val Acc: 16.27%\n",
      "  ‚úÖ Best model saved! (Val Acc: 16.27%)\n",
      "Epoch [14/30] | Train Loss: 2.7431 | Train Acc: 11.31% | Val Loss: nan | Val Acc: 15.06%\n",
      "Epoch [15/30] | Train Loss: 2.7615 | Train Acc: 13.12% | Val Loss: nan | Val Acc: 15.06%\n",
      "Epoch [16/30] | Train Loss: 2.7441 | Train Acc: 14.78% | Val Loss: nan | Val Acc: 16.87%\n",
      "  ‚úÖ Best model saved! (Val Acc: 16.87%)\n",
      "Epoch [17/30] | Train Loss: 2.7190 | Train Acc: 13.73% | Val Loss: nan | Val Acc: 15.66%\n",
      "Epoch [18/30] | Train Loss: 2.6857 | Train Acc: 13.73% | Val Loss: nan | Val Acc: 18.67%\n",
      "  ‚úÖ Best model saved! (Val Acc: 18.67%)\n",
      "Epoch [19/30] | Train Loss: 2.6736 | Train Acc: 15.54% | Val Loss: nan | Val Acc: 20.48%\n",
      "  ‚úÖ Best model saved! (Val Acc: 20.48%)\n",
      "Epoch [20/30] | Train Loss: 2.6149 | Train Acc: 16.89% | Val Loss: nan | Val Acc: 18.07%\n",
      "Epoch [21/30] | Train Loss: 2.6469 | Train Acc: 17.50% | Val Loss: nan | Val Acc: 16.87%\n",
      "Epoch [22/30] | Train Loss: 2.6415 | Train Acc: 18.55% | Val Loss: nan | Val Acc: 15.06%\n",
      "Epoch [23/30] | Train Loss: 2.6202 | Train Acc: 17.50% | Val Loss: nan | Val Acc: 20.48%\n",
      "Epoch [24/30] | Train Loss: 2.6134 | Train Acc: 19.00% | Val Loss: nan | Val Acc: 13.86%\n",
      "Epoch [25/30] | Train Loss: 2.6049 | Train Acc: 17.80% | Val Loss: nan | Val Acc: 17.47%\n",
      "Epoch [26/30] | Train Loss: 2.4903 | Train Acc: 22.17% | Val Loss: nan | Val Acc: 20.48%\n",
      "Epoch [27/30] | Train Loss: 2.4824 | Train Acc: 22.17% | Val Loss: nan | Val Acc: 20.48%\n",
      "Epoch [28/30] | Train Loss: 2.4001 | Train Acc: 23.68% | Val Loss: nan | Val Acc: 20.48%\n",
      "Epoch [29/30] | Train Loss: 2.3934 | Train Acc: 25.04% | Val Loss: nan | Val Acc: 21.69%\n",
      "  ‚úÖ Best model saved! (Val Acc: 21.69%)\n",
      "Epoch [30/30] | Train Loss: 2.3724 | Train Acc: 23.23% | Val Loss: nan | Val Acc: 22.29%\n",
      "  ‚úÖ Best model saved! (Val Acc: 22.29%)\n",
      "\n",
      "============================================================\n",
      "‚úÖ Training completed successfully!\n",
      "üèÜ Best Validation Accuracy: 22.29%\n",
      "‚è±Ô∏è  Total Training Time: 191m 60s\n",
      "üíæ Model saved as 'vgg19_scratch_stanford_cars_20classes.pth'\n",
      "============================================================\n",
      "\n",
      "üß™ Evaluating on Test Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11304\\1566989351.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_SAVE_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Test Loss: 2.5539 | Test Accuracy: 23.66%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import copy\n",
    "import time\n",
    "from data_preprocessing import get_dataloaders\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "MODEL_SAVE_PATH = 'vgg19_scratch_stanford_cars_20classes.pth'\n",
    "NUM_CLASSES = 20  # Updated to 20 classes\n",
    "BATCH_SIZE = 32   \n",
    "NUM_EPOCHS = 30 \n",
    "LEARNING_RATE = 0.01\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Hardware\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. ARCHITECTURE: VGG-19 (From Scratch)\n",
    "# ==========================================\n",
    "class VGG19_Scratch(nn.Module):\n",
    "    def __init__(self, num_classes=20):\n",
    "        super(VGG19_Scratch, self).__init__()\n",
    "        \n",
    "        # Helper: Conv -> BN -> ReLU\n",
    "        def conv_block(in_ch, out_ch):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch), # Critical for training deep VGG from scratch\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        # VGG-19 Configuration (2-2-4-4-4)\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1 (2 Convs)\n",
    "            conv_block(3, 64), conv_block(64, 64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Block 2 (2 Convs)\n",
    "            conv_block(64, 128), conv_block(128, 128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Block 3 (4 Convs)\n",
    "            conv_block(128, 256), conv_block(256, 256), conv_block(256, 256), conv_block(256, 256),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Block 4 (4 Convs)\n",
    "            conv_block(256, 512), conv_block(512, 512), conv_block(512, 512), conv_block(512, 512),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Block 5 (4 Convs)\n",
    "            conv_block(512, 512), conv_block(512, 512), conv_block(512, 512), conv_block(512, 512),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Classifier Head (Global Average Pooling for parameter efficiency)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "        \n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        # He/Kaiming Initialization is best for ReLU networks\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None: nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# ==========================================\n",
    "# 3. VALIDATION FUNCTION\n",
    "# ==========================================\n",
    "def validate_model(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the validation set.\n",
    "    \n",
    "    Returns:\n",
    "        val_loss: Average validation loss\n",
    "        val_acc: Validation accuracy (%)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss = running_loss / len(val_loader)\n",
    "    val_acc = 100 * correct_predictions / total_samples\n",
    "    \n",
    "    return val_loss, val_acc\n",
    "\n",
    "# ==========================================\n",
    "# 4. TRAINING ENGINE\n",
    "# ==========================================\n",
    "def train():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üöÄ VGG-19 From Scratch Training on 20 Random Classes\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # 1. Load Data using HF pipeline\n",
    "        print(\"\\nüì¶ Loading data from Hugging Face Hub...\")\n",
    "        train_loader, val_loader, test_loader, selected_classes, label_mapping = get_dataloaders(\n",
    "            batch_size=BATCH_SIZE, \n",
    "            img_size=IMG_SIZE, \n",
    "            num_workers=0,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nüéØ Selected Classes: {selected_classes}\")\n",
    "        print(f\"üìä Number of Classes: {len(selected_classes)}\")\n",
    "        print(f\"üíª Using device: {device}\")\n",
    "\n",
    "        # 2. Setup Model\n",
    "        print(\"\\nü§ñ Initializing VGG-19 from scratch...\")\n",
    "        model = VGG19_Scratch(num_classes=NUM_CLASSES).to(device)\n",
    "        \n",
    "        # SGD with Momentum is the gold standard for training CNNs from scratch\n",
    "        optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=5e-4)\n",
    "        \n",
    "        # Scheduler: Reduces LR when validation accuracy plateaus\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.1, patience=5, verbose=True\n",
    "        )\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        scaler = GradScaler()  # Mixed Precision for speed\n",
    "\n",
    "        # 3. Training Loop\n",
    "        best_val_acc = 0.0\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        start_time = time.time()\n",
    "\n",
    "        print(f\"\\nüèãÔ∏è Starting Training for {NUM_EPOCHS} epochs...\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            # ==========================================\n",
    "            # TRAINING PHASE\n",
    "            # ==========================================\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for i, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # AutoCast for Mixed Precision (Faster)\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            train_loss = running_loss / len(train_loader)\n",
    "            train_acc = 100 * correct / total\n",
    "            \n",
    "            # ==========================================\n",
    "            # VALIDATION PHASE\n",
    "            # ==========================================\n",
    "            val_loss, val_acc = validate_model(model, val_loader, criterion, device)\n",
    "            \n",
    "            # Update Scheduler\n",
    "            scheduler.step(val_acc)\n",
    "            \n",
    "            # Print Epoch Results\n",
    "            print(f\"Epoch [{epoch+1:2d}/{NUM_EPOCHS}] | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "            \n",
    "            # Save Best Model\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'val_acc': val_acc,\n",
    "                    'val_loss': val_loss,\n",
    "                    'selected_classes': selected_classes,\n",
    "                    'label_mapping': label_mapping\n",
    "                }, MODEL_SAVE_PATH)\n",
    "                print(f\"  ‚úÖ Best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚úÖ Training completed successfully!\")\n",
    "        print(f\"üèÜ Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "        print(f\"‚è±Ô∏è  Total Training Time: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "        print(f\"üíæ Model saved as '{MODEL_SAVE_PATH}'\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # ==========================================\n",
    "        # FINAL TEST EVALUATION\n",
    "        # ==========================================\n",
    "        print(\"\\nüß™ Evaluating on Test Set...\")\n",
    "        checkpoint = torch.load(MODEL_SAVE_PATH)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        test_loss, test_acc = validate_model(model, test_loader, criterion, device)\n",
    "        print(f\"üìà Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.2f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        train()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nüõë Training interrupted by user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69630ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
