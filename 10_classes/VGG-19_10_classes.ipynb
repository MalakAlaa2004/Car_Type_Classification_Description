{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295aaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üöÄ VGG-19 From Scratch Training on 20 Random Classes\n",
      "============================================================\n",
      "\n",
      "üì¶ Loading data from Hugging Face Hub...\n",
      "üöÄ Loading 'tanganke/stanford_cars' from Hugging Face Hub...\n",
      "üìä Total classes in dataset: 196\n",
      "üéØ Selected 10 random classes: [6, 26, 28, 35, 57, 62, 70, 163, 188, 189]\n",
      "‚úÖ Filtered dataset size: 410 samples\n",
      "üìä Total classes in dataset: 196\n",
      "üéØ Selected 10 random classes: [6, 26, 28, 35, 57, 62, 70, 163, 188, 189]\n",
      "‚úÖ Filtered dataset size: 406 samples\n",
      "‚úÖ Data Split: 328 Train | 82 Val | 406 Test\n",
      "üìå Classes remapped to range: 0-9\n",
      "\n",
      "üéØ Selected Classes: [6, 26, 28, 35, 57, 62, 70, 163, 188, 189]\n",
      "üìä Number of Classes: 10\n",
      "üíª Using device: cuda\n",
      "\n",
      "ü§ñ Initializing VGG-19 from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_12904\\2951918966.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # Mixed Precision for speed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèãÔ∏è Starting Training for 30 epochs...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_12904\\2951918966.py:189: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_12904\\2951918966.py:113: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 1/30] | Train Loss: 2.3060 | Train Acc: 10.98% | Val Loss: 2.3230 | Val Acc: 6.10%\n",
      "  ‚úÖ Best model saved! (Val Acc: 6.10%)\n",
      "Epoch [ 2/30] | Train Loss: 2.3307 | Train Acc: 12.80% | Val Loss: 2.3141 | Val Acc: 10.98%\n",
      "  ‚úÖ Best model saved! (Val Acc: 10.98%)\n",
      "Epoch [ 3/30] | Train Loss: 2.3142 | Train Acc: 10.06% | Val Loss: 2.2230 | Val Acc: 15.85%\n",
      "  ‚úÖ Best model saved! (Val Acc: 15.85%)\n",
      "Epoch [ 4/30] | Train Loss: 2.2721 | Train Acc: 13.11% | Val Loss: 2.2065 | Val Acc: 18.29%\n",
      "  ‚úÖ Best model saved! (Val Acc: 18.29%)\n",
      "Epoch [ 5/30] | Train Loss: 2.2937 | Train Acc: 13.11% | Val Loss: 2.1641 | Val Acc: 13.41%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import copy\n",
    "import time\n",
    "from data_preprocessing import get_dataloaders\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "MODEL_SAVE_PATH = 'vgg19_scratch_stanford_cars_10classes.pth'\n",
    "NUM_CLASSES = 10  # Updated to 20 classes\n",
    "BATCH_SIZE = 32   \n",
    "NUM_EPOCHS = 30 \n",
    "LEARNING_RATE = 0.01\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Hardware\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. ARCHITECTURE: VGG-19 (From Scratch)\n",
    "# ==========================================\n",
    "class VGG19_Scratch(nn.Module):\n",
    "    def __init__(self, num_classes=20):\n",
    "        super(VGG19_Scratch, self).__init__()\n",
    "        \n",
    "        # Helper: Conv -> BN -> ReLU\n",
    "        def conv_block(in_ch, out_ch):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch), # Critical for training deep VGG from scratch\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        # VGG-19 Configuration (2-2-4-4-4)\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1 (2 Convs)\n",
    "            conv_block(3, 64), conv_block(64, 64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Block 2 (2 Convs)\n",
    "            conv_block(64, 128), conv_block(128, 128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Block 3 (4 Convs)\n",
    "            conv_block(128, 256), conv_block(256, 256), conv_block(256, 256), conv_block(256, 256),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Block 4 (4 Convs)\n",
    "            conv_block(256, 512), conv_block(512, 512), conv_block(512, 512), conv_block(512, 512),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Block 5 (4 Convs)\n",
    "            conv_block(512, 512), conv_block(512, 512), conv_block(512, 512), conv_block(512, 512),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Classifier Head (Global Average Pooling for parameter efficiency)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "        \n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        # He/Kaiming Initialization is best for ReLU networks\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None: nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# ==========================================\n",
    "# 3. VALIDATION FUNCTION\n",
    "# ==========================================\n",
    "def validate_model(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the validation set.\n",
    "    \n",
    "    Returns:\n",
    "        val_loss: Average validation loss\n",
    "        val_acc: Validation accuracy (%)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss = running_loss / len(val_loader)\n",
    "    val_acc = 100 * correct_predictions / total_samples\n",
    "    \n",
    "    return val_loss, val_acc\n",
    "\n",
    "# ==========================================\n",
    "# 4. TRAINING ENGINE\n",
    "# ==========================================\n",
    "def train():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üöÄ VGG-19 From Scratch Training on 20 Random Classes\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # 1. Load Data using HF pipeline\n",
    "        print(\"\\nüì¶ Loading data from Hugging Face Hub...\")\n",
    "        train_loader, val_loader, test_loader, selected_classes, label_mapping = get_dataloaders(\n",
    "            batch_size=BATCH_SIZE, \n",
    "            img_size=IMG_SIZE, \n",
    "            num_workers=0,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nüéØ Selected Classes: {selected_classes}\")\n",
    "        print(f\"üìä Number of Classes: {len(selected_classes)}\")\n",
    "        print(f\"üíª Using device: {device}\")\n",
    "\n",
    "        # 2. Setup Model\n",
    "        print(\"\\nü§ñ Initializing VGG-19 from scratch...\")\n",
    "        model = VGG19_Scratch(num_classes=NUM_CLASSES).to(device)\n",
    "        \n",
    "        # SGD with Momentum is the gold standard for training CNNs from scratch\n",
    "        optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=5e-4)\n",
    "        \n",
    "        # Scheduler: Reduces LR when validation accuracy plateaus\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.1, patience=5, verbose=True\n",
    "        )\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        scaler = GradScaler()  # Mixed Precision for speed\n",
    "\n",
    "        # 3. Training Loop\n",
    "        best_val_acc = 0.0\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        start_time = time.time()\n",
    "\n",
    "        print(f\"\\nüèãÔ∏è Starting Training for {NUM_EPOCHS} epochs...\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            # ==========================================\n",
    "            # TRAINING PHASE\n",
    "            # ==========================================\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for i, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # AutoCast for Mixed Precision (Faster)\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            train_loss = running_loss / len(train_loader)\n",
    "            train_acc = 100 * correct / total\n",
    "            \n",
    "            # ==========================================\n",
    "            # VALIDATION PHASE\n",
    "            # ==========================================\n",
    "            val_loss, val_acc = validate_model(model, val_loader, criterion, device)\n",
    "            \n",
    "            # Update Scheduler\n",
    "            scheduler.step(val_acc)\n",
    "            \n",
    "            # Print Epoch Results\n",
    "            print(f\"Epoch [{epoch+1:2d}/{NUM_EPOCHS}] | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "            \n",
    "            # Save Best Model\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'val_acc': val_acc,\n",
    "                    'val_loss': val_loss,\n",
    "                    'selected_classes': selected_classes,\n",
    "                    'label_mapping': label_mapping\n",
    "                }, MODEL_SAVE_PATH)\n",
    "                print(f\"  ‚úÖ Best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚úÖ Training completed successfully!\")\n",
    "        print(f\"üèÜ Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "        print(f\"‚è±Ô∏è  Total Training Time: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "        print(f\"üíæ Model saved as '{MODEL_SAVE_PATH}'\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # ==========================================\n",
    "        # FINAL TEST EVALUATION\n",
    "        # ==========================================\n",
    "        print(\"\\nüß™ Evaluating on Test Set...\")\n",
    "        checkpoint = torch.load(MODEL_SAVE_PATH)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        test_loss, test_acc = validate_model(model, test_loader, criterion, device)\n",
    "        print(f\"üìà Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.2f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        train()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nüõë Training interrupted by user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69630ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
