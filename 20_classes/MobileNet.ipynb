{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef7ac154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üöÄ MobileNetV2 Training on 20 Random Classes\n",
      "============================================================\n",
      "\n",
      "üì¶ Loading data from Hugging Face Hub...\n",
      "üöÄ Loading 'tanganke/stanford_cars' from Hugging Face Hub...\n",
      "üìä Total classes in dataset: 196\n",
      "üéØ Selected 20 random classes: [6, 7, 8, 22, 23, 26, 28, 35, 55, 57, 59, 62, 70, 108, 139, 151, 163, 173, 188, 189]\n",
      "‚úÖ Filtered dataset size: 829 samples\n",
      "üìä Total classes in dataset: 196\n",
      "üéØ Selected 20 random classes: [6, 7, 8, 22, 23, 26, 28, 35, 55, 57, 59, 62, 70, 108, 139, 151, 163, 173, 188, 189]\n",
      "‚úÖ Filtered dataset size: 820 samples\n",
      "‚úÖ Data Split: 663 Train | 166 Val | 820 Test\n",
      "üìå Classes remapped to range: 0-19\n",
      "\n",
      "üéØ Selected Classes: [6, 7, 8, 22, 23, 26, 28, 35, 55, 57, 59, 62, 70, 108, 139, 151, 163, 173, 188, 189]\n",
      "üìä Number of Classes: 20\n",
      "\n",
      "ü§ñ Initializing MobileNetV2...\n",
      "üíª Using device: cuda\n",
      "\n",
      "üèãÔ∏è Starting Training for 30 epochs...\n",
      "============================================================\n",
      "Epoch [ 1/30] | Train Loss: 2.9684 | Train Acc: 8.60% | Val Loss: 2.9025 | Val Acc: 12.65%\n",
      "  ‚úÖ Best model saved! (Val Acc: 12.65%)\n",
      "Epoch [ 2/30] | Train Loss: 2.7852 | Train Acc: 20.21% | Val Loss: 2.7023 | Val Acc: 35.54%\n",
      "  ‚úÖ Best model saved! (Val Acc: 35.54%)\n",
      "Epoch [ 3/30] | Train Loss: 2.5261 | Train Acc: 32.73% | Val Loss: 2.4412 | Val Acc: 39.76%\n",
      "  ‚úÖ Best model saved! (Val Acc: 39.76%)\n",
      "Epoch [ 4/30] | Train Loss: 2.2108 | Train Acc: 43.89% | Val Loss: 2.1012 | Val Acc: 45.18%\n",
      "  ‚úÖ Best model saved! (Val Acc: 45.18%)\n",
      "Epoch [ 5/30] | Train Loss: 1.8781 | Train Acc: 50.83% | Val Loss: 1.8557 | Val Acc: 47.59%\n",
      "  ‚úÖ Best model saved! (Val Acc: 47.59%)\n",
      "Epoch [ 6/30] | Train Loss: 1.5550 | Train Acc: 59.28% | Val Loss: 1.6397 | Val Acc: 56.02%\n",
      "  ‚úÖ Best model saved! (Val Acc: 56.02%)\n",
      "Epoch [ 7/30] | Train Loss: 1.2980 | Train Acc: 67.27% | Val Loss: 1.4436 | Val Acc: 61.45%\n",
      "  ‚úÖ Best model saved! (Val Acc: 61.45%)\n",
      "Epoch [ 8/30] | Train Loss: 1.0292 | Train Acc: 75.11% | Val Loss: 1.3566 | Val Acc: 63.86%\n",
      "  ‚úÖ Best model saved! (Val Acc: 63.86%)\n",
      "Epoch [ 9/30] | Train Loss: 0.8713 | Train Acc: 77.68% | Val Loss: 1.2230 | Val Acc: 65.06%\n",
      "  ‚úÖ Best model saved! (Val Acc: 65.06%)\n",
      "Epoch [10/30] | Train Loss: 0.7142 | Train Acc: 81.60% | Val Loss: 1.1669 | Val Acc: 69.28%\n",
      "  ‚úÖ Best model saved! (Val Acc: 69.28%)\n",
      "Epoch [11/30] | Train Loss: 0.5683 | Train Acc: 85.82% | Val Loss: 1.1419 | Val Acc: 65.66%\n",
      "Epoch [12/30] | Train Loss: 0.4602 | Train Acc: 88.54% | Val Loss: 1.0544 | Val Acc: 65.66%\n",
      "Epoch [13/30] | Train Loss: 0.3854 | Train Acc: 90.95% | Val Loss: 1.0228 | Val Acc: 69.28%\n",
      "Epoch [14/30] | Train Loss: 0.3420 | Train Acc: 91.40% | Val Loss: 1.0362 | Val Acc: 66.87%\n",
      "Epoch [15/30] | Train Loss: 0.2711 | Train Acc: 95.48% | Val Loss: 1.0002 | Val Acc: 71.08%\n",
      "  ‚úÖ Best model saved! (Val Acc: 71.08%)\n",
      "Epoch [16/30] | Train Loss: 0.2403 | Train Acc: 95.78% | Val Loss: 1.0168 | Val Acc: 68.07%\n",
      "Epoch [17/30] | Train Loss: 0.2042 | Train Acc: 96.68% | Val Loss: 0.9840 | Val Acc: 71.69%\n",
      "  ‚úÖ Best model saved! (Val Acc: 71.69%)\n",
      "Epoch [18/30] | Train Loss: 0.1591 | Train Acc: 97.29% | Val Loss: 1.0058 | Val Acc: 73.49%\n",
      "  ‚úÖ Best model saved! (Val Acc: 73.49%)\n",
      "Epoch [19/30] | Train Loss: 0.1488 | Train Acc: 97.13% | Val Loss: 1.0180 | Val Acc: 69.88%\n",
      "Epoch [20/30] | Train Loss: 0.1479 | Train Acc: 96.53% | Val Loss: 1.0150 | Val Acc: 66.27%\n",
      "Epoch [21/30] | Train Loss: 0.1150 | Train Acc: 98.79% | Val Loss: 1.0397 | Val Acc: 69.88%\n",
      "Epoch [22/30] | Train Loss: 0.0957 | Train Acc: 98.64% | Val Loss: 1.0119 | Val Acc: 69.28%\n",
      "Epoch [23/30] | Train Loss: 0.0898 | Train Acc: 98.64% | Val Loss: 1.0154 | Val Acc: 68.67%\n",
      "Epoch [24/30] | Train Loss: 0.0951 | Train Acc: 99.10% | Val Loss: 0.9964 | Val Acc: 69.88%\n",
      "Epoch [25/30] | Train Loss: 0.0813 | Train Acc: 98.79% | Val Loss: 0.9822 | Val Acc: 70.48%\n",
      "Epoch [26/30] | Train Loss: 0.0843 | Train Acc: 98.79% | Val Loss: 0.9863 | Val Acc: 69.28%\n",
      "Epoch [27/30] | Train Loss: 0.0925 | Train Acc: 98.04% | Val Loss: 0.9793 | Val Acc: 69.28%\n",
      "Epoch [28/30] | Train Loss: 0.0917 | Train Acc: 99.10% | Val Loss: 0.9951 | Val Acc: 69.88%\n",
      "Epoch [29/30] | Train Loss: 0.0744 | Train Acc: 99.55% | Val Loss: 0.9791 | Val Acc: 70.48%\n",
      "Epoch [30/30] | Train Loss: 0.0918 | Train Acc: 98.79% | Val Loss: 0.9734 | Val Acc: 70.48%\n",
      "\n",
      "============================================================\n",
      "‚úÖ Training completed successfully!\n",
      "üèÜ Best Validation Accuracy: 73.49%\n",
      "üíæ Model saved as 'mobilenet_v2_stanford_cars_20classes.pth'\n",
      "============================================================\n",
      "\n",
      "üß™ Evaluating on Test Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_29144\\2242005540.py:191: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_SAVE_PATH)['model_state_dict'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Test Loss: 0.8266 | Test Accuracy: 73.29%\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import get_dataloaders\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "MODEL_SAVE_PATH = \"mobilenet_v2_stanford_cars_20classes.pth\"\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 20  # Updated to 20 classes\n",
    "NUM_EPOCHS = 30\n",
    "IMG_SIZE = 224  # Image resolution for MobileNetV2\n",
    "\n",
    "# ==========================================\n",
    "# 2. MODEL ARCHITECTURE\n",
    "# ==========================================\n",
    "def get_mobilenet_model(num_classes=20):\n",
    "    # Load Pre-trained MobileNetV2\n",
    "    model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    # --- STRATEGY: FINE-TUNING ---\n",
    "    # 1. Freeze the early layers (generic features like lines/edges)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    # 2. Unfreeze the last few inverted residual blocks for better feature learning\n",
    "    # MobileNetV2 has features organized in a Sequential container\n",
    "    # Unfreeze the last 4 blocks (out of 19 total blocks)\n",
    "    for param in model.features[-4:].parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    # 3. Replace the Classifier Head with Higher Dropout\n",
    "    in_features = model.classifier[1].in_features  # MobileNetV2 has 1280 features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(in_features, 1024),  # Add an intermediate layer\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),                # INCREASED dropout\n",
    "        nn.Linear(1024, num_classes)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ==========================================\n",
    "# 3. VALIDATION FUNCTION\n",
    "# ==========================================\n",
    "def validate_model(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the validation set.\n",
    "    \n",
    "    Returns:\n",
    "        val_loss: Average validation loss\n",
    "        val_acc: Validation accuracy (%)\n",
    "    \"\"\"\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss = running_loss / len(val_loader)\n",
    "    val_acc = 100 * correct_predictions / total_samples\n",
    "    \n",
    "    return val_loss, val_acc\n",
    "\n",
    "# ==========================================\n",
    "# 4. TRAINING WITH VALIDATION\n",
    "# ==========================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üöÄ MobileNetV2 Training on 20 Random Classes\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # 1. Load Data using HF pipeline (handles downloading, splitting, and transforms)\n",
    "        print(\"\\nüì¶ Loading data from Hugging Face Hub...\")\n",
    "        train_dl, val_dl, test_dl, selected_classes, label_mapping = get_dataloaders(\n",
    "            batch_size=BATCH_SIZE, \n",
    "            img_size=IMG_SIZE, \n",
    "            num_workers=0,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nüéØ Selected Classes: {selected_classes}\")\n",
    "        print(f\"üìä Number of Classes: {len(selected_classes)}\")\n",
    "        \n",
    "        print(\"\\nü§ñ Initializing MobileNetV2...\")\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"üíª Using device: {device}\")\n",
    "        \n",
    "        model = get_mobilenet_model(num_classes=NUM_CLASSES).to(device)\n",
    "        \n",
    "        # Hyperparameters\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "        \n",
    "        # Learning Rate Scheduler (now based on validation loss)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.1, patience=3, verbose=True\n",
    "        )\n",
    "        \n",
    "        # Track best validation accuracy for model saving\n",
    "        best_val_acc = 0.0\n",
    "        \n",
    "        print(f\"\\nüèãÔ∏è Starting Training for {NUM_EPOCHS} epochs...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            # ==========================================\n",
    "            # TRAINING PHASE\n",
    "            # ==========================================\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0 \n",
    "            total_samples = 0\n",
    "            \n",
    "            for images, labels in train_dl:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                # Track Accuracy during training\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_samples += labels.size(0)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            train_loss = running_loss / len(train_dl)\n",
    "            train_acc = 100 * correct_predictions / total_samples\n",
    "            \n",
    "            # ==========================================\n",
    "            # VALIDATION PHASE\n",
    "            # ==========================================\n",
    "            val_loss, val_acc = validate_model(model, val_dl, criterion, device)\n",
    "            \n",
    "            # Print epoch results\n",
    "            print(f\"Epoch [{epoch+1:2d}/{NUM_EPOCHS}] | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "            \n",
    "            # Update learning rate based on validation loss\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            # Save best model based on validation accuracy\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                torch.save({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'val_acc': val_acc,\n",
    "                    'val_loss': val_loss,\n",
    "                    'selected_classes': selected_classes,\n",
    "                    'label_mapping': label_mapping\n",
    "                }, MODEL_SAVE_PATH)\n",
    "                print(f\"  ‚úÖ Best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚úÖ Training completed successfully!\")\n",
    "        print(f\"üèÜ Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "        print(f\"üíæ Model saved as '{MODEL_SAVE_PATH}'\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # ==========================================\n",
    "        # FINAL TEST EVALUATION\n",
    "        # ==========================================\n",
    "        print(\"\\nüß™ Evaluating on Test Set...\")\n",
    "        model.load_state_dict(torch.load(MODEL_SAVE_PATH)['model_state_dict'])\n",
    "        test_loss, test_acc = validate_model(model, test_dl, criterion, device)\n",
    "        print(f\"üìà Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"\\n‚ùå An error occurred during execution:\")\n",
    "        print(e)\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85a443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
