{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ad1fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Standardized Pipeline...\n",
      "Loading training data from ready_data_splits/train_split.csv...\n",
      "Loading validation data from ready_data_splits/val_split.csv...\n",
      "Initializing ResNet50...\n",
      "Starting Training on cuda...\n",
      "Epoch 1/15 | Loss: 5.1178 | Accuracy: 2.49%\n",
      "Epoch 2/15 | Loss: 4.1305 | Accuracy: 10.19%\n",
      "Epoch 3/15 | Loss: 3.1685 | Accuracy: 20.60%\n",
      "Epoch 4/15 | Loss: 2.4130 | Accuracy: 34.95%\n",
      "Epoch 5/15 | Loss: 1.8673 | Accuracy: 47.08%\n",
      "Epoch 6/15 | Loss: 1.4298 | Accuracy: 59.55%\n",
      "Epoch 7/15 | Loss: 1.1141 | Accuracy: 67.58%\n",
      "Epoch 8/15 | Loss: 0.9054 | Accuracy: 73.31%\n",
      "Epoch 9/15 | Loss: 0.7432 | Accuracy: 78.17%\n",
      "Epoch 10/15 | Loss: 0.6267 | Accuracy: 81.43%\n",
      "Epoch 11/15 | Loss: 0.5394 | Accuracy: 84.66%\n",
      "Epoch 12/15 | Loss: 0.4202 | Accuracy: 87.66%\n",
      "Epoch 13/15 | Loss: 0.3788 | Accuracy: 89.13%\n",
      "Epoch 14/15 | Loss: 0.3380 | Accuracy: 90.04%\n",
      "Epoch 15/15 | Loss: 0.2742 | Accuracy: 92.35%\n",
      "Training loop finished successfully!\n",
      "Saving model...\n",
      "Model saved as 'resnet50_stanford_cars.pth'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from model_utils import UniversalCarDataset, get_transforms  # Import your tools\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "# Update this path to where your `prepare_data.py` saved the CSVs\n",
    "DATA_DIR = \"ready_data_splits\" \n",
    "MODEL_SAVE_PATH = \"resnet50_stanford_cars.pth\"\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 196\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "# ==========================================\n",
    "# 2. MODEL ARCHITECTURE\n",
    "# ==========================================\n",
    "def get_resnet_model(num_classes=196):\n",
    "    # Load Pre-trained ResNet50\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    # --- STRATEGY: FINE-TUNING ---\n",
    "    # 1. Freeze the early layers (generic features like lines/edges)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    # 2. Unfreeze the last TWO blocks for better feature learning (Optional but recommended)\n",
    "    for param in model.layer3.parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in model.layer4.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    # 3. Replace the Head with Higher Dropout\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(in_features, 1024), # Add an intermediate layer\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),              # INCREASED from 0.3 to 0.5\n",
    "        nn.Linear(1024, num_classes)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ==========================================\n",
    "# 3. TRAINING SKELETON\n",
    "# ==========================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Check if splits exist\n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        print(f\"Error: Data directory '{DATA_DIR}' not found.\")\n",
    "        print(\"Please run 'prepare_data.py' first to generate splits.\")\n",
    "    else:\n",
    "        print(\"Initializing Standardized Pipeline...\")\n",
    "        \n",
    "        try:\n",
    "            # 1. Get Standard Transforms\n",
    "            tfms = get_transforms(img_size=(224, 224))\n",
    "\n",
    "            # 2. Load the Saved Splits\n",
    "            print(f\"Loading training data from {DATA_DIR}/train_split.csv...\")\n",
    "            train_ds = UniversalCarDataset(f\"{DATA_DIR}/train_split.csv\", transform=tfms['train'])\n",
    "            \n",
    "            print(f\"Loading validation data from {DATA_DIR}/val_split.csv...\")\n",
    "            val_ds = UniversalCarDataset(f\"{DATA_DIR}/val_split.csv\", transform=tfms['val'])\n",
    "\n",
    "            # 3. Create Loaders\n",
    "            train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "            val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "            \n",
    "            print(\"Initializing ResNet50...\")\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            model = get_resnet_model(num_classes=NUM_CLASSES).to(device)\n",
    "            \n",
    "            # Hyperparameters\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            # Add weight_decay=1e-4\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "            \n",
    "            # Learning Rate Scheduler\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "            \n",
    "            print(f\"Starting Training on {device}...\")\n",
    "            \n",
    "            for epoch in range(NUM_EPOCHS):\n",
    "                model.train()\n",
    "                running_loss = 0.0\n",
    "                correct_predictions = 0 \n",
    "                total_samples = 0\n",
    "                \n",
    "                for images, labels in train_dl:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    running_loss += loss.item()\n",
    "                    \n",
    "                    # Track Accuracy during training to see progress\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    total_samples += labels.size(0)\n",
    "                    correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "                epoch_loss = running_loss / len(train_dl)\n",
    "                epoch_acc = 100 * correct_predictions / total_samples\n",
    "                \n",
    "                print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%\")\n",
    "                \n",
    "                # Update LR based on training loss (or validation loss if we computed it per epoch)\n",
    "                scheduler.step(epoch_loss)\n",
    "                \n",
    "            print(\"Training loop finished successfully!\")\n",
    "            print(\"Saving model...\")\n",
    "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "            print(f\"Model saved as '{MODEL_SAVE_PATH}'\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"\\n An error occurred during execution:\")\n",
    "            print(e)\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
